{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yungGenos/cronometro/blob/main/atividade_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------\n",
        "# RA 421110705 - kaique vinicius souza genonadio da silva\n",
        "# RA "
      ],
      "metadata": {
        "id": "4pSDFKIyLew7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pacotes necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import xgboost\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor \n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Medidas de avaliação\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "6SL7PlyjQvMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IRqaU4ArVHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_taxi_ny_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8RRQpieicHi",
        "outputId": "81963fc4-522b-4f52-d089-ab7e82676d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1458644 entries, 0 to 1458643\n",
            "Data columns (total 11 columns):\n",
            " #   Column              Non-Null Count    Dtype  \n",
            "---  ------              --------------    -----  \n",
            " 0   id                  1458644 non-null  object \n",
            " 1   vendor_id           1458644 non-null  int64  \n",
            " 2   pickup_datetime     1458644 non-null  object \n",
            " 3   dropoff_datetime    1458644 non-null  object \n",
            " 4   passenger_count     1458644 non-null  int64  \n",
            " 5   pickup_longitude    1458644 non-null  float64\n",
            " 6   pickup_latitude     1458644 non-null  float64\n",
            " 7   dropoff_longitude   1458644 non-null  float64\n",
            " 8   dropoff_latitude    1458644 non-null  float64\n",
            " 9   store_and_fwd_flag  1458644 non-null  object \n",
            " 10  trip_duration       1458644 non-null  int64  \n",
            "dtypes: float64(4), int64(3), object(4)\n",
            "memory usage: 122.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Listando as colunas do arquivo de dados\n",
        "df_taxi_ny_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh8J9_h4idj-",
        "outputId": "d66519e6-9df8-476c-9280-fa9e8e73a688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'vendor_id', 'pickup_datetime', 'dropoff_datetime',\n",
              "       'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
              "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
              "       'trip_duration'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciTgr_qWJO-b",
        "outputId": "b1a2f96a-41bb-4d9b-9174-59ff75427a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Conexão com o drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega a biblioteca pandas e atribui um alias chamado \"pd\"\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RClyc12WJZp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deixar colunas e linhas aparentes\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "# Faz a leitura do arquivo train.csv \n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/taxi_ny_train.csv')"
      ],
      "metadata": {
        "id": "yVzWFOBkKOnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1Pesquise o significado dos hiperparâmetros tanto para o Random Forest quanto para o XGBOOST\n",
        "\n",
        "#Os hiperparâmetros (hyperparameters) são ajustes que podem ser definidos antes do treinamento do modelo e que têm um impacto significativo no desempenho do modelo. O Random Forest e o XGBoost são algoritmos de aprendizado de máquina que possuem hiperparâmetros diferentes. A seguir, vou explicar os hiperparâmetros mais comuns para cada um deles:\n",
        "\n",
        "#Hiperparâmetros do Random Forest:\n",
        "#n_estimators: O número de árvores de decisão no modelo. Valores maiores geralmente melhoram o desempenho, mas aumentam o tempo de treinamento e o uso de memória.\n",
        "#min_samples_split: O número mínimo de amostras necessárias para dividir um nó interno. Valores menores podem levar a uma árvore mais complexa e overfitting, enquanto valores maiores podem levar a uma árvore menos flexível.\n",
        "#min_samples_leaf: O número mínimo de amostras necessárias em uma folha. Valores menores podem levar a overfitting, enquanto valores maiores podem levar a uma árvore menos flexível.\n",
        "#max_features: O número máximo de recursos que cada árvore é permitida a considerar para fazer uma divisão. Valores menores podem reduzir a variância, mas podem aumentar o viés.\n",
        "\n",
        "#Hiperparâmetros do XGBoost:\n",
        "#learning_rate: O tamanho do passo de atualização em cada iteração enquanto se movimenta em direção ao mínimo da função de perda. Valores menores reduzem o viés, mas aumentam o tempo de treinamento.\n",
        "#max_depth: A profundidade máxima de cada árvore de decisão. Valores maiores geralmente aumentam o desempenho, mas também podem aumentar o risco de overfitting.\n",
        "#min_child_weight: O número mínimo de amostras necessárias em cada nó. Valores maiores podem levar a uma árvore mais conservadora, enquanto valores menores podem levar a overfitting.\n",
        "#subsample: A fração de amostras a serem usadas para cada árvore de decisão. Valores menores podem reduzir a variância, mas podem aumentar o viés.\n",
        "#colsample_bytree: A fração de recursos a serem usados para cada árvore de decisão. Valores menores podem reduzir a variância, mas podem aumentar o viés.\n",
        "#Estes são apenas alguns dos hiperparâmetros disponíveis para cada modelo. É importante destacar que a escolha de valores apropriados para esses hiperparâmetros pode ser um processo complexo e envolve experimentação e ajuste fino."
      ],
      "metadata": {
        "id": "DEUzL70ELd_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Justifique a escolha dos hiperparâmetros com a explicação \n",
        "\n",
        "#Ao usar o hiperparâmetro random forest, é possível escolher um número aleatório de árvores dentro de um determinado intervalo. Esse método pode ajudar a encontrar um número ótimo de árvores que equilibre a precisão do modelo com sua eficiência. \n",
        "#No entanto, temos  em mente que a escolha do número ideal de árvores pode variar dependendo do conjunto de dados e do problema específico que estamos tentando resolver. Portanto, \n",
        "#é sempre importante experfrom sklearn.ensemble import RandomForestClassifie\n",
        "\n"
      ],
      "metadata": {
        "id": "YWyP6jULNQmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Altere o percentual de treino e teste\n",
        "\n",
        "# Separando as informações em y e x\n",
        "y = df_taxi_ny_train['trip_duration']\n",
        "X = df_taxi_ny_train.drop('trip_duration', axis=1)\n",
        "\n",
        "# Separando as informações do arquivo de dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)"
      ],
      "metadata": {
        "id": "1YC0Ppn1Q5z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Criando o objeto da regressão Random Forest com alguns hiperparâmetros \n",
        "rf_regressor = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', random_state=42)\n",
        "\n",
        "# modelo\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# teste\n",
        "y_pred = rf_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "C5by48M-xdqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Aplique os algoritmos com 3 hiperparâmetros\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "# Leitura do arquivo CSV com pandas\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/taxi_ny_train.csv')\n",
        "\n",
        "# Separando as features das labels\n",
        "X = df.drop('trip_duration', axis=1)\n",
        "y = df['trip_duration']\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Definindo a grade de hiperparâmetros para busca aleatória\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth}\n",
        "\n",
        "# Criando o objeto da regressão Random Forest\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Instanciando o objeto de busca aleatória\n",
        "rf_random = RandomizedSearchCV(estimator = rf_regressor, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, \n",
        "                               cv = 3, \n",
        "                               verbose=2, \n",
        "                               random_state=42, \n",
        "                               n_jobs = -1)\n",
        "\n",
        "# Treinando o modelo com busca aleatória de hiperparâmetros\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Exibindo os melhores parâmetros encontrados\n",
        "print(rf_random.best_params_)\n",
        "\n",
        "# Treinando o modelo com os melhores hiperparâmetros\n",
        "best_rf = RandomForestRegressor(n_estimators=500,\n",
        "                                 max_features='sqrt',\n",
        "                                 max_depth=50,\n",
        "                                 random_state=42)\n",
        "\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Avaliando o modelo nos dados de teste\n",
        "y_pred = best_rf.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6IOw8YOJw6Jk",
        "outputId": "44774f59-3b1f-4fc1-a667-7f7ff5dce1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-298f3835883e>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Treinando o modelo com busca aleatória de hiperparâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Exibindo os melhores parâmetros encontrados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 300 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'id1952620'\n\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'id2209155'\n"
          ]
        }
      ]
    }
  ]
}